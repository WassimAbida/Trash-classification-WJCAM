{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(path, f_name):\n",
    "    \n",
    "    X_data=[]\n",
    "    y_data=[]\n",
    "    data_path = os.path.join(path, '{}.csv'.format(f_name))\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    X_id = data['id_image'].values\n",
    "    Y = data['label_image'].values\n",
    "    \n",
    "    for file in X_id:\n",
    "        img = cv2.imread(os.path.join(path, \"images\", str(file)))\n",
    "        X_data.append(np.asarray(img))                    \n",
    "    \n",
    "    return (np.array(X_data),np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = loading_data(path_to_data, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the shape of the date to ensure that it is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {}\n",
    "for new_data_point in y_data :\n",
    "    \n",
    "    if new_data_point in distributions:\n",
    "        distributions[new_data_point] += 1\n",
    "    else:\n",
    "        distributions[new_data_point] = 1\n",
    "    \n",
    "\n",
    "plt.bar(distributions.keys(), distributions.values());\n",
    "\n",
    "plt.ylabel('number of images ')\n",
    "plt.title('classes')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the 3 classes \"city\", \"forest\" and \"non dechet\" have more data than the classes \"medical waste\" and \"domestique\". So we should consider the fact the dataset is unbalanced in our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show here some images (one image for each classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 40))\n",
    "L=[3,144,282,351,500]\n",
    "titles=list(np.unique(y_data))\n",
    "for i in range(5):\n",
    "    ax=plt.subplot(1,5,i+1)\n",
    "    plt.imshow(X_data[L[i]])\n",
    "    plt.title(titles[i])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we notice that even the photo of \"non dechet\" class is taken in a forest, so the model must be able to detect the place where the photo is taken, if there is trash or not and sometimes the type of the trash (like the case of medical waste class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file.\n",
    "The csv file containes the id and the labels of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"data/train.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels of classes are strings, so we change our labels to numerical labels using dicto_generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictio_generator(s):\n",
    "    d = dict()\n",
    "    id_dictionnaire = 0\n",
    "    d[s[0]] = id_dictionnaire\n",
    "     \n",
    "    for c in s : \n",
    "        if c not in d : \n",
    "            id_dictionnaire+= 1\n",
    "            d[c] = id_dictionnaire\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming  categorical Labels into numeric ones \n",
    "dicta = dictio_generator(np.unique(y_data))\n",
    "y_data_numeric = np.array([ dicta[i] for i in y_data ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data on train and test sets to test our model manually. However, we will not need this split to run the model on the ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data_numeric, test_size=0.33, random_state=42)\n",
    "print ('x_train size: ' , X_train.shape)\n",
    "print ('x_test size:  ' , X_test.shape)\n",
    "print ('y_train size: ' , y_train.shape)\n",
    "print ('y_test size:  ' , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 6 classes. Thus, we need to use One hot encoding method to have a better representation of our targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test  = X_test.astype('float32') / 255.\n",
    "one_hot_encoded_y_train = keras.utils.to_categorical(y_train,len(dicta))\n",
    "one_hot_encoded_y_test = keras.utils.to_categorical(y_test,len(dicta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When managing images, data with high level complexity, we thought of Deep Neural networks as models capable of extracting features in an automatic way.\n",
    "\n",
    "for that, using keras package we developed  a convolutional neural net with two hidden layer and a fully connected part that outputs a vector with dimension (num_classes,1)\n",
    "\n",
    "\n",
    "Model is as such: \n",
    "\n",
    "   ![Alt text](https://jhui.github.io/assets/cnn/convolution_b1.png)\n",
    "   \n",
    "Where each layer is extracting more relative features from previous representation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we upload the necessary packages which are more likely to be used to develop the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D \n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "from keras.utils import np_utils \n",
    "from keras.callbacks import TensorBoard \n",
    "from keras import regularizers \n",
    "from time import time \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fix the hyper-parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1671) # for reproducibility\n",
    "# network and training\n",
    "\n",
    "NB_EPOCH = 10 # number of epochs/episodes \n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "\n",
    "VALIDATION_SPLIT=0.1 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.3\n",
    "num_classes = 5 # number of outputs = number of digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have implementing a simple neural network define by:\n",
    "![Alt text](./graph/architecture.png\")\n",
    "Model is defined as such "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation=None, input_shape=(128,128,3)))\n",
    "model.add(Conv2D(32,  (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add( Conv2D (64,(3,3), activation = 'relu'))\n",
    "model.add( Conv2D (64,(3,3), activation = 'relu'))\n",
    "model.add( MaxPooling2D ( pool_size =(2,2)))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "          \n",
    "        \n",
    "sgd = SGD(lr=0.01, decay=0, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "        \n",
    "# training and fitting the model \n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs_CNN', histogram_freq=0, \n",
    "                            batch_size=32, \n",
    "                            write_graph=True, \n",
    "                            write_grads=True, write_images=True,\n",
    "                            embeddings_freq=0, embeddings_layer_names=None,\n",
    "                            embeddings_metadata=None)\n",
    "\n",
    "\"\"\" tensorboard --logdir ./logs_CNN\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any training, we need to resize the images in the goal that they matches the input shape of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resize = np.zeros(( len(X_train), 128, 128, 3))\n",
    "for i in range(len(X_train)):\n",
    "    X_train_resize[i] = cv2.resize(X_train[i], (128, 128))\n",
    "    \n",
    "X_test_resize = np.zeros(( len(X_test), 128, 128, 3))\n",
    "for i in range(len(X_test)):\n",
    "    X_test_resize[i] = cv2.resize(X_test[i], (128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our neural network for a fixed number of epochs and with the respect to the other hyper-parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_resize, one_hot_encoded_y_train, batch_size=BATCH_SIZE,\n",
    "                   epochs=NB_EPOCH,validation_split = VALIDATION_SPLIT,\n",
    "          callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then move on analysing the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics evaluation \n",
    "#tensorboard --logdir=logs/\n",
    "score = model.evaluate(X_test_resize, one_hot_encoded_y_test, verbose=VERBOSE,batch_size=BATCH_SIZE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, an important point to verify is to check if we are learning something and not overfitting and learning too much about our train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard logs \n",
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint : if the gap between the train plot and the validation one is too large, then we are facing an overfitting problem \n",
    "we might want to adjust our hyper-parameters, or manage our data set size..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second variant of CNN: CNN + Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a relatively small data set, one way to adress the overfitting problem is to use the data augmentation method,\n",
    "meaning apply basic modifications on input images such as ( flip, zoom, random noise, rotation...).\n",
    "\n",
    "We then conserve the information within our input data and enlarge our data set, which has strong impact on our metrics results and the model performance.\n",
    "\n",
    "One might use the keras ImageDataGeneraor and choose the type of modifications to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In chase of computation limitations, we might generate data while performing the training of the network, in a way to not lose much time and space to create new data points(images) and save them in independant folders which might take huge space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maintain the same structure of the model, but this time we fit our model with data generated from data augmentation process, hyper-parameters could be adjusted also as needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train_resize)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history_augmented = model.fit_generator(datagen.flow(X_train_resize, one_hot_encoded_y_train, batch_size=BATCH_SIZE),\n",
    "                    steps_per_epoch=len(X_train_resize) / 32, epochs=NB_EPOCH,validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we porceed to evaluate our model efficiency, when evaluating the model, we should maintain the same transformations applied to our train data as well for our test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen= datagen.flow(X_test_resize, one_hot_encoded_y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSeg = model.evaluate_generator(test_datagen, 100)\n",
    "print(\"loss_function\",scoreSeg[0], \"Accuracy = \",scoreSeg[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you find a good model, you have to write an ImageClassifier class on the goal to do a submission.<br/>\n",
    "Here, is a example of ImageClassifier class implementing the model explain above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./submissions/starting_kit/image_classifier.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "\n",
    "class ImageClassifier(object):\n",
    "\n",
    "    def __init__(self, batch_size=32, epochs=1, validation_split=0.2, dropout=0.3, input_shape_image=(128, 128)):\n",
    "        \n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.step_per_epoch = 20\n",
    "        self.input_image_shape = input_shape_image\n",
    "        self.input_shape = self.input_image_shape + (3,)\n",
    "        self.dropout = dropout\n",
    "        self.validation_split = validation_split\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _transform(self, x):   \n",
    "        x = x / 255.\n",
    "        x_resize = cv2.resize(x, self.input_image_shape)\n",
    "        return x_resize\n",
    "    \n",
    "    def data_augmentation(self, X):\n",
    "        datagen = ImageDataGenerator(\n",
    "                featurewise_center=True,\n",
    "                featurewise_std_normalization=True,\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "        # compute quantities required for featurewise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied)\n",
    "        \n",
    "        datagen.fit(X)\n",
    "        return datagen\n",
    "\n",
    "    def fit(self, img_loader):\n",
    "        nb = len(img_loader)\n",
    "        X = np.zeros((nb,) + self.input_shape)\n",
    "        Y = np.zeros((nb, 5))\n",
    "        \n",
    "        for i in range(nb):\n",
    "            x, y = img_loader.load(i)\n",
    "            X[i] = self._transform(x)\n",
    "            Y[i, y] = 1\n",
    "            \n",
    "        datagen = self.data_augmentation(X)\n",
    "        \n",
    "        self.model.fit_generator(datagen.flow(X, Y, batch_size=self.batch_size), steps_per_epoch=self.step_per_epoch, epochs=self.epochs)\n",
    "     \n",
    "    def predict_proba(self, img_loader):\n",
    "        nb = len(img_loader)\n",
    "        X = np.zeros((nb, 128, 128, 3))\n",
    "        for i in range(nb):\n",
    "            X[i] = self._transform(img_loader.load(i))\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "\n",
    "        model.add(Conv2D(32, (3,3), activation=None, input_shape=self.input_shape))\n",
    "        model.add(Conv2D(32,  (3,3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "        model.add(Dropout(self.dropout))\n",
    "\n",
    "        model.add( Conv2D (64,(3,3), activation = 'relu'))\n",
    "        model.add( Conv2D (64,(3,3), activation = 'relu'))\n",
    "        model.add( MaxPooling2D ( pool_size =(2,2)))\n",
    "        model.add(Dropout(self.dropout))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256,activation = 'relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "          \n",
    "        \n",
    "        sgd = SGD(lr=0.01, decay=0, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Testing Before Submitted to Ramp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to test your submissions files before doing your submissions. In that goal, use ramp_test_submission command. Notice that this unit test run in the folder [`submissions/starting_kit`](/tree/submissions/starting_kit).\n",
    "Before running the test, make sure you have done the following tasks:\n",
    "\n",
    "- install ramp-workflow\n",
    "- write the python file image_classifier.py and put it in the following folder [`submissions/starting_kit`].\n",
    "- download the data by excuting `python download_data.py`\n",
    "\n",
    "You have two possibility to test your submissions, a complete test (train and test the model with cross validtion like the server or a quick test (just to make sure the submissions code are working). If the test run, print train and test erros on each fold of the cross validation you can then submit to ramp.\n",
    "\n",
    "Execute the following cell to do a quick test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ramp_test_submission --quick-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following cell to do a complete test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Trash classification\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining .\\submissions\\starting_kit ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "Epoch 1/1\n",
      "\n",
      " 1/20 [>.............................] - ETA: 1:49 - loss: 1.5126 - acc: 0.3438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      " 3/20 [===>..........................] - ETA: 33s - loss: 2.1459 - acc: 0.2292 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      " 5/20 [======>.......................] - ETA: 17s - loss: 1.8872 - acc: 0.3000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      " 7/20 [=========>....................] - ETA: 11s - loss: 1.8019 - acc: 0.2902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      " 9/20 [============>.................] - ETA: 7s - loss: 1.7383 - acc: 0.3021 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "11/20 [===============>..............] - ETA: 5s - loss: 1.7034 - acc: 0.2898\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "13/20 [==================>...........] - ETA: 3s - loss: 1.6633 - acc: 0.3005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "15/20 [=====================>........] - ETA: 2s - loss: 1.6132 - acc: 0.3090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "17/20 [========================>.....] - ETA: 1s - loss: 1.6117 - acc: 0.2947\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "18/20 [==========================>...] - ETA: 0s - loss: 1.6034 - acc: 0.2991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 1.5917 - acc: 0.3064\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "20/20 [==============================] - 7s 353ms/step - loss: 1.5855 - acc: 0.3113\n",
      "\t\u001b[38;5;178m\u001b[1mscore    acc\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.158\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.173\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.160\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore          acc\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.158\u001b[0m \u001b[38;5;150m±\u001b[0m \u001b[38;5;150m0.0\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.173\u001b[0m \u001b[38;5;105m±\u001b[0m \u001b[38;5;105m0.0\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m    \u001b[38;5;1m\u001b[1m0.16\u001b[0m \u001b[38;5;218m±\u001b[0m \u001b[38;5;218m0.0\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore    acc\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.173\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.160\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-27 23:28:52.336430: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2019-01-27 23:28:52.929231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\n",
      "pciBusID: 0000:03:00.0\n",
      "totalMemory: 12.00GiB freeMemory: 11.59GiB\n",
      "2019-01-27 23:28:52.929231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2019-01-27 23:28:53.537632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-01-27 23:28:53.537632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2019-01-27 23:28:53.537632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2019-01-27 23:28:53.553232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11213 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\n",
      "c:\\users\\hard med lenovo\\appdata\\local\\conda\\conda\\envs\\python 3.6\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\cloudpickle\\cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!ramp_test_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
